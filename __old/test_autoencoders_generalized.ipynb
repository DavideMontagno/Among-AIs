{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Autoencoder map diifernt dimension\n",
    "## Mock Map Dataset\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "square=\"................~............@@@\\n##....X........~.....e.......@@@\\n###..GJ.........~.@@g$$.....@@.@\\n..#...........~~..@..$..@@@@@@@@\\n.#.....&......~~..@@@$..@@@@@@@@\\n...#...........~.@@@@@@@@@@@@@@@\\n.....#...........@@@@@@.@@@@@@@@\\n...###........$...@.@@@#.@@@@@@@\\n....###@..#.......@@@....@@@@...\\n...##@@@@.##......@....##@@.....\\n.....@@@@@##...@@@@......@@.....\\n.@@@@@@@@@#@@@@@@@@.@..##..#....\\n.@@@@@@@@@@.@@@@@@@@@..###.x.&..\\n..@@.@.@@@..@@@@@@@@@..##.......\\n...@.@@@@@@@@....@@@@#..#...#...\\n..@@.@@@@@@@@@..........#####...\\n.@@@@@@@@@.@@.........##.#.#.#..\\n.@@@@@@@@@..&.....c..#########..\\n.@@@@@@@@@......a.f.#.#.#.###...\\n..@@@K.............h.########...\\n...@@..H.........b...##.######..\\n..@@@............$$.##..#######.\\n....&......#........########.##.\\n..B.........#........##.#..##.#.\\n......D...#.#...#....#..####.#..\\n$$.............#.i...#.....##...\\n...........##....#.##..#..#.....\\n..$A.......#.##..##...#....@@@..\\n...C.I.....##.....##.#.#...@@@..\\n..EF.......##....j..###...@@@@@@\\n...........##.......##......@@@.\\n................#...##.#...@@@@@\"\n",
    "square_my_symbol=\"a\"\n",
    "square_enemies=\"upper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle=\"................~............@@@\\n##....X........~.....e.......@@@\\n###..GJ.........~.@@g$$.....@@.@\\n..#...........~~..@..$..@@@@@@@@\\n.#.....&......~~..@@@$..@@@@@@@@\\n...#...........~.@@@@@@@@@@@@@@@\\n.....#...........@@@@@@.@@@@@@@@\\n...###........$...@.@@@#.@@@@@@@\\n....###@..#.......@@@....@@@@...\\n...##@@@@.##......@....##@@.....\\n.....@@@@@##...@@@@......@@.....\\n.@@@@@@@@@#@@@@@@@@.@..##..#....\\n.@@@@@@@@@@.@@@@@@@@@..###.x.&..\\n..@@.@.@@@..@@@@@@@@@..##.......\\n...@.@@@@@@@@....@@@@#..#...#...\\n..@@.@@@@@@@@@..........#####...\\n.@@@@@@@@@.@@.........##.#.#.#..\\n.@@@@@@@@@..&.....c..#########..\\n.@@@@@@@@@......a.f.#.#.#.###...\\n..@@@K.............h.########...\\n...@@..H.........b...##.######..\\n..@@@............$$.##..#######.\\n....&......#........########.##.\\n..B.........#........##.#..##.#.\\n......D...#.#...#....#..####.#..\\n$$.............#.i...#.....##...\\n...........##....#.##..#..#.....\\n..$A.......#.##..##...#....@@@..\\n...C.I.....##.....##.#.#...@@@..\\n..EF.......##....j..###...@@@@@@\\n...........##.......##......@@@.\\n................#...##.#...@@@@@\"\n",
    "rectangle_my_symbol=\"a\"\n",
    "rectangle_enemies=\"upper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_symbol=[(square,square_my_symbol,square_enemies),(rectangle,rectangle_my_symbol, rectangle_enemies),(square,square_my_symbol,square_enemies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw=[]\n",
    "for elem in dataset_symbol:\n",
    "    mappa_processed=[]\n",
    "    for line in elem[0].splitlines():\n",
    "        line_content=[]\n",
    "        for symbol in line:\n",
    "            line_content.append(symbol)\n",
    "        mappa_processed.append(line_content)\n",
    "\n",
    "    dataset_raw.append((np.array(mappa_processed),elem[1],elem[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([['.', '.', '.', ..., '@', '@', '@'],\n",
       "        ['#', '#', '.', ..., '@', '@', '@'],\n",
       "        ['#', '#', '#', ..., '@', '.', '@'],\n",
       "        ...,\n",
       "        ['.', '.', 'E', ..., '@', '@', '@'],\n",
       "        ['.', '.', '.', ..., '@', '@', '.'],\n",
       "        ['.', '.', '.', ..., '@', '@', '@']], dtype='<U1'), 'a', 'upper')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataset_raw[0]"
   ]
  },
  {
   "source": [
    "## Process dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed=[]\n",
    "for image,current_symbol,current_enemies in dataset_raw:\n",
    "    this_image=[]\n",
    "    for row in range(len(image[0])):\n",
    "        this_row=[]\n",
    "        for column in range(len(image[1])):\n",
    "            current_cell=image[row][column]\n",
    "\n",
    "            #Immettere infor per i bonus\n",
    "            if(current_cell == \"#\" or current_cell == \"@\" or current_cell == \"!\" or current_cell == \"&\"):\n",
    "                result = 0.8\n",
    "            elif(current_cell==\"X\"):\n",
    "                if(current_enemies==\"upper\"):\n",
    "                    result=0.2\n",
    "                else:\n",
    "                    result=0.4\n",
    "            elif(current_cell==\"x\"):\n",
    "                if(current_enemies==\"upper\"):\n",
    "                    result=0.4\n",
    "                else:\n",
    "                    result=0.2\n",
    "            elif(current_cell==current_symbol):\n",
    "                result=0\n",
    "            elif(current_cell.isupper() and current_enemies==\"upper\"):\n",
    "                result = 0.6\n",
    "            elif(current_cell.islower() and current_enemies==\"lower\"):\n",
    "                result = 0.6 \n",
    "            else:\n",
    "                result = 0.0\n",
    "            this_row.append(result)\n",
    "        this_image.append(this_row)\n",
    "    dataset_processed.append(np.array(this_image))\n",
    "dataset_processed=np.array(dataset_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0.8, ..., 0.8, 0. , 0.8],\n",
       "       ...,\n",
       "       [0. , 0. , 0.6, ..., 0.8, 0.8, 0.8],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0. ],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0.8]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset_processed[0]"
   ]
  },
  {
   "source": [
    "## Autoencoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "latent_dim_encoder=64\n",
    "max_map_dimension=128\n",
    "latent_dim_decoder=max_map_dimension*max_map_dimension\n",
    "# Si producono delle mappe 128x128 anche se sono piÃ¹ piccole poi si tagliano\n"
   ]
  },
  {
   "source": [
    "### Generalize Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed_generalized=[]\n",
    "for elem in dataset_processed:\n",
    "    extension = np.empty((max_map_dimension,max_map_dimension))\n",
    "    extension.fill(0.95)\n",
    "    extension[:elem.shape[0],:elem.shape[1]] = elem\n",
    "    dataset_processed_generalized.append(extension)\n",
    "dataset_processed_generalized=np.array(dataset_processed_generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim_encoder, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(latent_dim_decoder, activation='sigmoid'),\n",
    "      layers.Reshape((max_map_dimension, max_map_dimension))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n(3, 128, 128)\n(3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train=dataset_processed_generalized\n",
    "x_test=dataset_processed_generalized\n",
    "print(type(x_test))\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "poch 803/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - val_loss: 0.0025\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d6a812908>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "autoencoder=Autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1000,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('ml_models/autoencoder/autoencoder_weights.wg')\n",
    "#\n",
    "# tf.keras.models.save_model(autoencoder,'autoencoder.h5',save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_image(decoded_image):\n",
    "    list_values=[0,0.2,0.4,0.6,0.8,0.95]\n",
    "\n",
    "    for row in range(len(decoded_image[0])):\n",
    "        for column in range(len(decoded_image[1])):\n",
    "            current_cell=decoded_image[row][column]\n",
    "            differences=[abs(current_cell-elem)for elem in list_values]\n",
    "            decoded_image[row][column]=list_values[differences.index(min(differences))]\n",
    "    return decoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , ..., 0.95, 0.95, 0.95],\n",
       "       [0.8 , 0.8 , 0.  , ..., 0.95, 0.95, 0.95],\n",
       "       [0.8 , 0.8 , 0.8 , ..., 0.95, 0.95, 0.95],\n",
       "       ...,\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95],\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95],\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , ..., 0.95, 0.95, 0.95],\n",
       "       [0.8 , 0.95, 0.  , ..., 0.95, 0.95, 0.95],\n",
       "       [0.8 , 0.8 , 0.8 , ..., 0.95, 0.95, 0.95],\n",
       "       ...,\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95],\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95],\n",
       "       [0.95, 0.95, 0.95, ..., 0.95, 0.95, 0.95]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "post_process_image(decoded_imgs[0])"
   ]
  },
  {
   "source": [
    "## Mock dataset sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "max_len_sequence=5\n",
    "input_output_dim=64\n",
    "num_lstm_cell=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=np.array([dataset_processed_generalized[0],dataset_processed_generalized[1],dataset_processed_generalized[2]])\n",
    "sequence_extra=np.array([dataset_processed_generalized[0],dataset_processed_generalized[1]])\n",
    "\n",
    "dataset_sequences=np.array([sequence,sequence,sequence,sequence_extra])\n",
    "\n",
    "x_train_encoded_sequences=[]\n",
    "y_train_encoded_sequences=[]\n",
    "for current_sequence in dataset_sequences:\n",
    "    encoded_imgs = autoencoder.encoder(current_sequence).numpy()\n",
    "    y_train_encoded_sequences.append(encoded_imgs[-1])\n",
    "    x_train_encoded_sequences.append(encoded_imgs[:-1])\n",
    "\n",
    "x_train=np.array(x_train_encoded_sequences)\n",
    "y_train=np.array(y_train_encoded_sequences)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train, maxlen=max_len_sequence,padding=\"post\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "source": [
    "## LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(max_len_sequence, input_output_dim)),\n",
    "    #tf.keras.layers.Embedding(input_dim=max_len_sequence, output_dim=input_output_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(num_lstm_cell),\n",
    "    tf.keras.layers.Dense(units=input_output_dim)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2692.7444 - mse: 2692.7444\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2686.6511 - mse: 2686.6511\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2679.9180 - mse: 2679.9180\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2673.7014 - mse: 2673.7014\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2666.4680 - mse: 2666.4680\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d7002e508>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "lstm_model.fit(x=x_train, y=y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('ml_models/lstm/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}