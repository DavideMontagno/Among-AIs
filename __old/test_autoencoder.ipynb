{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Autoencoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Mock dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa1=\"................~............@@@\\n##....X........~.....e.......@@@\\n###..GJ.........~.@@g$$.....@@.@\\n..#...........~~..@..$..@@@@@@@@\\n.#.....&......~~..@@@$..@@@@@@@@\\n...#...........~.@@@@@@@@@@@@@@@\\n.....#...........@@@@@@.@@@@@@@@\\n...###........$...@.@@@#.@@@@@@@\\n....###@..#.......@@@....@@@@...\\n...##@@@@.##......@....##@@.....\\n.....@@@@@##...@@@@......@@.....\\n.@@@@@@@@@#@@@@@@@@.@..##..#....\\n.@@@@@@@@@@.@@@@@@@@@..###.x.&..\\n..@@.@.@@@..@@@@@@@@@..##.......\\n...@.@@@@@@@@....@@@@#..#...#...\\n..@@.@@@@@@@@@..........#####...\\n.@@@@@@@@@.@@.........##.#.#.#..\\n.@@@@@@@@@..&.....c..#########..\\n.@@@@@@@@@......a.f.#.#.#.###...\\n..@@@K.............h.########...\\n...@@..H.........b...##.######..\\n..@@@............$$.##..#######.\\n....&......#........########.##.\\n..B.........#........##.#..##.#.\\n......D...#.#...#....#..####.#..\\n$$.............#.i...#.....##...\\n...........##....#.##..#..#.....\\n..$A.......#.##..##...#....@@@..\\n...C.I.....##.....##.#.#...@@@..\\n..EF.......##....j..###...@@@@@@\\n...........##.......##......@@@.\\n................#...##.#...@@@@@\"\n",
    "my_symbol=\"a\"\n",
    "enemies=\"upper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa1_processed=[]\n",
    "for elem in mappa1.splitlines():\n",
    "    line=[]\n",
    "    for symbol in elem:\n",
    "        line.append(symbol)\n",
    "    mappa1_processed.append(line)\n",
    "\n",
    "mappa1_processed=np.array(mappa1_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['.', '.', '.', ..., '@', '@', '@'],\n",
       "       ['#', '#', '.', ..., '@', '@', '@'],\n",
       "       ['#', '#', '#', ..., '@', '.', '@'],\n",
       "       ...,\n",
       "       ['.', '.', 'E', ..., '@', '@', '@'],\n",
       "       ['.', '.', '.', ..., '@', '@', '.'],\n",
       "       ['.', '.', '.', ..., '@', '@', '@']], dtype='<U1')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "mappa1_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw=[(mappa1_processed,my_symbol,enemies),(mappa1_processed,my_symbol,enemies),(mappa1_processed,my_symbol,enemies),(mappa1_processed,my_symbol,enemies),(mappa1_processed,my_symbol,enemies)]"
   ]
  },
  {
   "source": [
    "## Process dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed=[]\n",
    "for image,current_symbol,current_enemies in dataset_raw:\n",
    "    this_image=[]\n",
    "    for row in range(len(image[0])):\n",
    "        this_row=[]\n",
    "        for column in range(len(image[1])):\n",
    "            current_cell=image[row][column]\n",
    "\n",
    "            #Immettere infor per i bonus\n",
    "            if(current_cell == \"#\" or current_cell == \"@\" or current_cell == \"!\" or current_cell == \"&\"):\n",
    "                result = 0.8\n",
    "            elif(current_cell==\"X\"):\n",
    "                if(enemies==\"upper\"):\n",
    "                    result=0.2\n",
    "                else:\n",
    "                    result=0.4\n",
    "            elif(current_cell==\"x\"):\n",
    "                if(enemies==\"upper\"):\n",
    "                    result=0.4\n",
    "                else:\n",
    "                    result=0.2\n",
    "            elif(current_cell==current_symbol):\n",
    "                result=0\n",
    "            elif(current_cell.isupper() and current_enemies==\"upper\"):\n",
    "                result = 0.6\n",
    "            elif(current_cell.islower() and current_enemies==\"lower\"):\n",
    "                result = 0.6 \n",
    "            else:\n",
    "                result = 0.0\n",
    "            this_row.append(result)\n",
    "        this_image.append(this_row)\n",
    "    dataset_processed.append(np.array(this_image))\n",
    "dataset_processed=np.array(dataset_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0.8, ..., 0.8, 0. , 0.8],\n",
       "       ...,\n",
       "       [0. , 0. , 0.6, ..., 0.8, 0.8, 0.8],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0. ],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0.8]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataset_processed[1]"
   ]
  },
  {
   "source": [
    "## Autoencoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "latent_dim = 64 \n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(1024, activation='sigmoid'),\n",
    "      layers.Reshape((32, 32))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder=Autoencoder(latent_dim)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n(5, 32, 32)\n(5, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train=dataset_processed\n",
    "x_test=dataset_processed\n",
    "print(type(x_test))\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23ms/step - loss: 3.0981e-06 - val_loss: 3.0917e-06\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0917e-06 - val_loss: 3.0853e-06\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0853e-06 - val_loss: 3.0789e-06\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0789e-06 - val_loss: 3.0726e-06\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0726e-06 - val_loss: 3.0662e-06\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0662e-06 - val_loss: 3.0599e-06\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0599e-06 - val_loss: 3.0536e-06\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0536e-06 - val_loss: 3.0473e-06\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0473e-06 - val_loss: 3.0411e-06\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0411e-06 - val_loss: 3.0349e-06\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0349e-06 - val_loss: 3.0286e-06\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0286e-06 - val_loss: 3.0224e-06\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0224e-06 - val_loss: 3.0163e-06\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0163e-06 - val_loss: 3.0101e-06\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0101e-06 - val_loss: 3.0040e-06\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0040e-06 - val_loss: 2.9978e-06\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9978e-06 - val_loss: 2.9917e-06\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9917e-06 - val_loss: 2.9857e-06\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9857e-06 - val_loss: 2.9796e-06\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9796e-06 - val_loss: 2.9735e-06\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9735e-06 - val_loss: 2.9675e-06\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.9675e-06 - val_loss: 2.9615e-06\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.9615e-06 - val_loss: 2.9555e-06\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9555e-06 - val_loss: 2.9495e-06\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9495e-06 - val_loss: 2.9436e-06\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9436e-06 - val_loss: 2.9376e-06\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9376e-06 - val_loss: 2.9317e-06\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9317e-06 - val_loss: 2.9258e-06\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9258e-06 - val_loss: 2.9199e-06\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9199e-06 - val_loss: 2.9140e-06\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9140e-06 - val_loss: 2.9082e-06\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.9082e-06 - val_loss: 2.9024e-06\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9024e-06 - val_loss: 2.8965e-06\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8965e-06 - val_loss: 2.8907e-06\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8907e-06 - val_loss: 2.8850e-06\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.8850e-06 - val_loss: 2.8792e-06\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8792e-06 - val_loss: 2.8734e-06\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.8734e-06 - val_loss: 2.8677e-06\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.8677e-06 - val_loss: 2.8620e-06\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.8620e-06 - val_loss: 2.8563e-06\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8563e-06 - val_loss: 2.8506e-06\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8506e-06 - val_loss: 2.8450e-06\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.8450e-06 - val_loss: 2.8393e-06\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8393e-06 - val_loss: 2.8337e-06\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8337e-06 - val_loss: 2.8281e-06\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.8281e-06 - val_loss: 2.8225e-06\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8225e-06 - val_loss: 2.8169e-06\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.8169e-06 - val_loss: 2.8113e-06\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8113e-06 - val_loss: 2.8058e-06\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8058e-06 - val_loss: 2.8003e-06\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8003e-06 - val_loss: 2.7947e-06\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7947e-06 - val_loss: 2.7892e-06\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7892e-06 - val_loss: 2.7838e-06\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7838e-06 - val_loss: 2.7783e-06\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7783e-06 - val_loss: 2.7728e-06\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7728e-06 - val_loss: 2.7674e-06\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7674e-06 - val_loss: 2.7620e-06\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7620e-06 - val_loss: 2.7566e-06\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7566e-06 - val_loss: 2.7512e-06\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7512e-06 - val_loss: 2.7458e-06\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7458e-06 - val_loss: 2.7405e-06\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7405e-06 - val_loss: 2.7351e-06\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7351e-06 - val_loss: 2.7298e-06\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7298e-06 - val_loss: 2.7245e-06\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7245e-06 - val_loss: 2.7192e-06\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7192e-06 - val_loss: 2.7139e-06\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7139e-06 - val_loss: 2.7087e-06\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7087e-06 - val_loss: 2.7034e-06\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7034e-06 - val_loss: 2.6982e-06\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6982e-06 - val_loss: 2.6930e-06\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.6930e-06 - val_loss: 2.6877e-06\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6877e-06 - val_loss: 2.6826e-06\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6826e-06 - val_loss: 2.6774e-06\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6774e-06 - val_loss: 2.6722e-06\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6722e-06 - val_loss: 2.6671e-06\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.6671e-06 - val_loss: 2.6619e-06\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.6619e-06 - val_loss: 2.6568e-06\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6568e-06 - val_loss: 2.6517e-06\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6517e-06 - val_loss: 2.6466e-06\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6466e-06 - val_loss: 2.6416e-06\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6416e-06 - val_loss: 2.6365e-06\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6365e-06 - val_loss: 2.6315e-06\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6315e-06 - val_loss: 2.6265e-06\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.6265e-06 - val_loss: 2.6214e-06\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.6214e-06 - val_loss: 2.6164e-06\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6164e-06 - val_loss: 2.6114e-06\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6114e-06 - val_loss: 2.6065e-06\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6065e-06 - val_loss: 2.6015e-06\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.6015e-06 - val_loss: 2.5966e-06\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5966e-06 - val_loss: 2.5916e-06\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.5916e-06 - val_loss: 2.5867e-06\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.5867e-06 - val_loss: 2.5818e-06\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.5818e-06 - val_loss: 2.5769e-06\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5769e-06 - val_loss: 2.5721e-06\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5721e-06 - val_loss: 2.5672e-06\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5672e-06 - val_loss: 2.5624e-06\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5624e-06 - val_loss: 2.5575e-06\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.5575e-06 - val_loss: 2.5527e-06\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5527e-06 - val_loss: 2.5479e-06\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5479e-06 - val_loss: 2.5431e-06\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.5431e-06 - val_loss: 2.5383e-06\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5383e-06 - val_loss: 2.5335e-06\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5335e-06 - val_loss: 2.5288e-06\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.5288e-06 - val_loss: 2.5241e-06\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5241e-06 - val_loss: 2.5193e-06\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5193e-06 - val_loss: 2.5146e-06\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5146e-06 - val_loss: 2.5099e-06\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5099e-06 - val_loss: 2.5052e-06\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5052e-06 - val_loss: 2.5005e-06\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5005e-06 - val_loss: 2.4959e-06\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4959e-06 - val_loss: 2.4912e-06\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4912e-06 - val_loss: 2.4866e-06\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.4866e-06 - val_loss: 2.4820e-06\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.4820e-06 - val_loss: 2.4774e-06\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.4774e-06 - val_loss: 2.4728e-06\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4728e-06 - val_loss: 2.4682e-06\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4682e-06 - val_loss: 2.4636e-06\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4636e-06 - val_loss: 2.4590e-06\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.4590e-06 - val_loss: 2.4545e-06\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.4545e-06 - val_loss: 2.4500e-06\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4500e-06 - val_loss: 2.4454e-06\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4454e-06 - val_loss: 2.4409e-06\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4409e-06 - val_loss: 2.4364e-06\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4364e-06 - val_loss: 2.4319e-06\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4319e-06 - val_loss: 2.4275e-06\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4275e-06 - val_loss: 2.4230e-06\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4230e-06 - val_loss: 2.4186e-06\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4186e-06 - val_loss: 2.4141e-06\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.4141e-06 - val_loss: 2.4097e-06\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4097e-06 - val_loss: 2.4053e-06\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4053e-06 - val_loss: 2.4009e-06\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.4009e-06 - val_loss: 2.3965e-06\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3965e-06 - val_loss: 2.3921e-06\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3921e-06 - val_loss: 2.3877e-06\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3877e-06 - val_loss: 2.3834e-06\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3834e-06 - val_loss: 2.3790e-06\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3790e-06 - val_loss: 2.3747e-06\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3747e-06 - val_loss: 2.3704e-06\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3704e-06 - val_loss: 2.3661e-06\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3661e-06 - val_loss: 2.3618e-06\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3618e-06 - val_loss: 2.3575e-06\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3575e-06 - val_loss: 2.3532e-06\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3532e-06 - val_loss: 2.3490e-06\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3490e-06 - val_loss: 2.3447e-06\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3447e-06 - val_loss: 2.3405e-06\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3405e-06 - val_loss: 2.3362e-06\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3362e-06 - val_loss: 2.3320e-06\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3320e-06 - val_loss: 2.3278e-06\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3278e-06 - val_loss: 2.3236e-06\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3236e-06 - val_loss: 2.3194e-06\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3194e-06 - val_loss: 2.3153e-06\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3153e-06 - val_loss: 2.3111e-06\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3111e-06 - val_loss: 2.3070e-06\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3070e-06 - val_loss: 2.3028e-06\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3028e-06 - val_loss: 2.2987e-06\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2987e-06 - val_loss: 2.2946e-06\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2946e-06 - val_loss: 2.2905e-06\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2905e-06 - val_loss: 2.2864e-06\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2864e-06 - val_loss: 2.2823e-06\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2823e-06 - val_loss: 2.2782e-06\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2782e-06 - val_loss: 2.2742e-06\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2742e-06 - val_loss: 2.2701e-06\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.2701e-06 - val_loss: 2.2661e-06\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2661e-06 - val_loss: 2.2620e-06\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2620e-06 - val_loss: 2.2580e-06\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2580e-06 - val_loss: 2.2540e-06\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2540e-06 - val_loss: 2.2500e-06\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.2500e-06 - val_loss: 2.2460e-06\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2460e-06 - val_loss: 2.2420e-06\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2420e-06 - val_loss: 2.2381e-06\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2381e-06 - val_loss: 2.2341e-06\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2341e-06 - val_loss: 2.2302e-06\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2302e-06 - val_loss: 2.2262e-06\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2262e-06 - val_loss: 2.2223e-06\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2223e-06 - val_loss: 2.2184e-06\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2184e-06 - val_loss: 2.2145e-06\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2145e-06 - val_loss: 2.2106e-06\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2106e-06 - val_loss: 2.2067e-06\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2067e-06 - val_loss: 2.2028e-06\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.2028e-06 - val_loss: 2.1989e-06\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1989e-06 - val_loss: 2.1951e-06\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1951e-06 - val_loss: 2.1912e-06\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1912e-06 - val_loss: 2.1874e-06\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1874e-06 - val_loss: 2.1836e-06\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28eaaddd3c8>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1000,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(encoded_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_image(decoded_image):\n",
    "    list_values=[0,0.2,0.4,0.6,0.8]\n",
    "\n",
    "    for row in range(len(decoded_image[0])):\n",
    "        for column in range(len(decoded_image[1])):\n",
    "            current_cell=decoded_image[row][column]\n",
    "            differences=[abs(current_cell-elem)for elem in list_values]\n",
    "            decoded_image[row][column]=list_values[differences.index(min(differences))]\n",
    "    return decoded_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0. , ..., 0.8, 0.8, 0.8],\n",
       "       [0.8, 0.8, 0.8, ..., 0.8, 0. , 0.8],\n",
       "       ...,\n",
       "       [0. , 0. , 0.6, ..., 0.8, 0.8, 0.8],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0. ],\n",
       "       [0. , 0. , 0. , ..., 0.8, 0.8, 0.8]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "post_process_image(decoded_imgs[0])"
   ]
  },
  {
   "source": [
    "## Mock statset sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=[dataset_processed[0],dataset_processed[1],dataset_processed[2]]\n",
    "dataset_sequences=np.array([sequence,sequence,sequence])\n",
    "encoded_sequences=[]\n",
    "for sequence_one in dataset_sequences:\n",
    "    encoded_imgs = autoencoder.encoder(sequence_one).numpy()\n",
    "    encoded_sequences.append(encoded_imgs)\n",
    "x_train=np.array(encoded_sequences)\n",
    "y_train=np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299]], dtype=float32),\n",
       " array([[ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299]], dtype=float32),\n",
       " array([[ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299],\n",
       "        [ 0.      ,  8.985762,  0.      ,  9.236497,  7.241758,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.071447,  7.774665,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      , 10.020109,  0.      ,  9.851858,  9.137993,  0.      ,\n",
       "         10.253996,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  0.      ,  0.      ,  9.378804,  0.      ,  0.      ,\n",
       "          0.      ,  8.063891,  9.001828,  0.      ,  0.      ,  9.984906,\n",
       "          9.49766 ,  7.328406,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          0.      ,  9.649704,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "          8.987841,  9.553394,  0.      ,  0.      ,  0.      ,  8.790589,\n",
       "         10.647666,  8.029093,  0.      ,  9.269299]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "encoded_sequences"
   ]
  },
  {
   "source": [
    "# Lstm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(3, 64)),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(units=64)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 998us/step - loss: 28.8813 - mse: 28.8813\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.3894 - mse: 28.3894\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.7312 - mse: 27.7312\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.4835 - mse: 27.4835\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.2572 - mse: 27.2572\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28ead145088>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "lstm_model.fit(x=x_train, y=y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=np.array(lstm_model.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.4],\n",
       "       [0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.6],\n",
       "       [0.6, 0.4, 0.6, ..., 0.6, 0.4, 0.6],\n",
       "       ...,\n",
       "       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.6],\n",
       "       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.4],\n",
       "       [0.4, 0.4, 0.6, ..., 0.4, 0.6, 0.6]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "post_process_image(autoencoder.decoder(predicted).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predicted=autoencoder.decoder(predicted).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processed_prediction=[]\n",
    "for elem in decode_predicted:\n",
    "    current=post_process_image(elem)\n",
    "    post_processed_prediction.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([[0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.4],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.6],\n       [0.6, 0.4, 0.6, ..., 0.6, 0.4, 0.6],\n       ...,\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.6],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.4],\n       [0.4, 0.4, 0.6, ..., 0.4, 0.6, 0.6]], dtype=float32), array([[0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.4],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.6],\n       [0.6, 0.4, 0.6, ..., 0.6, 0.4, 0.6],\n       ...,\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.6],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.4],\n       [0.4, 0.4, 0.6, ..., 0.4, 0.6, 0.6]], dtype=float32), array([[0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.4],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.4, 0.6],\n       [0.6, 0.4, 0.6, ..., 0.6, 0.4, 0.6],\n       ...,\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.6],\n       [0.4, 0.4, 0.4, ..., 0.6, 0.6, 0.4],\n       [0.4, 0.4, 0.6, ..., 0.4, 0.6, 0.6]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(post_processed_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}